# Sign-Language-and-Gesture-Recognition

Projects is divided into 3 parts : 

1. Given an image of static gesture, predict what alphabet it represents.

2. Given an image of a person's upper body and hand, locate the hand and classify the gesture.

3. Given a video sequence of a series of frames, determine the word being spelled out.

Dataset : Images which represent different letters of the alphabet in the form of hand signals. 20 different native signers were chosen with approximately 5000 images for training.

Stack : Python with scikit-learn library.
